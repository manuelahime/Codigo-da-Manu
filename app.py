import streamlit as st
import spacy
import google.generativeai as genai
from gnews import GNews
from wordcloud import WordCloud
import re

# --- Configura√ß√£o da P√°gina e Fun√ß√µes Essenciais ---

# Configura o t√≠tulo da p√°gina e o layout
st.set_page_config(page_title="An√°lise Pol√≠tica", layout="wide")

# Carrega o modelo Spacy para Portugu√™s (cache para performance)
@st.cache_resource
def load_spacy_model():
    """Carrega o modelo 'pt_core_news_sm' do Spacy."""
    return spacy.load("pt_core_news_sm")

nlp = load_spacy_model()

# Configura a API do Gemini
try:
    # Tenta carregar a API Key dos segredos do Streamlit
    GEMINI_API_KEY = st.secrets["GEMINI_API_KEY"]
    genai.configure(api_key=GEMINI_API_KEY)
    model = genai.GenerativeModel('gemini-2.5-flash')
except (KeyError, FileNotFoundError):
    st.error("Chave de API do Gemini n√£o encontrada. Por favor, adicione-a ao arquivo `.streamlit/secrets.toml`.")
    model = None

# --- Fun√ß√µes de L√≥gica do Aplicativo ---

def fetch_news(deputy_name):
    """Busca not√≠cias usando GNews para o nome do deputado."""
    try:
        google_news = GNews(language='pt', country='BR', max_results=10)
        # Adiciona "deputado federal" para especificar a busca
        search_query = f'"{deputy_name}" deputado federal'
        articles = google_news.get_news(search_query)
        
        if not articles:
            st.warning("Nenhuma not√≠cia recente encontrada para este parlamentar.")
            return None, None

        # Concatena t√≠tulos e descri√ß√µes
        full_text = " ".join([
            (art['title'] + " " + art['description']) 
            for art in articles if art['description']
        ])
        
        return full_text, articles
    except Exception as e:
        st.error(f"Erro ao buscar not√≠cias: {e}")
        return None, None

def summarize_with_gemini(text_to_summarize):
    """Envia o texto das not√≠cias para o Gemini e retorna um resumo."""
    if not model:
        return "Erro: Modelo Gemini n√£o foi inicializado."

    prompt = f"""
    Voc√™ √© um analista pol√≠tico s√™nior.
    Com base nos seguintes t√≠tulos e descri√ß√µes de not√≠cias recentes, gere um resumo conciso e informativo.
    Identifique os fatos centrais e os temas mais prementes associados ao parlamentar mencionado.

    Not√≠cias:
    {text_to_summarize}

    Resumo Anal√≠tico:
    """
    try:
        response = model.generate_content(prompt)
        return response.text
    except Exception as e:
        st.error(f"Erro ao gerar resumo com o Gemini: {e}")
        return "N√£o foi poss√≠vel gerar o resumo."

def clean_text_and_generate_wordcloud(text, deputy_name):
    """Limpa o texto (stopwords, pontua√ß√£o, nome do deputado) e gera a nuvem de palavras."""
    
    # 1. Processar o texto com Spacy
    doc = nlp(text.lower())
    
    # 2. Obter partes do nome do deputado para remo√ß√£o
    name_parts = deputy_name.lower().split()
    
    # 3. Lemmatiza√ß√£o e remo√ß√£o de stopwords, pontua√ß√£o e o nome
    lemmas = []
    for token in doc:
        if (
            not token.is_stop and     # Remove stopwords (ex: 'o', 'de', 'para')
            not token.is_punct and    # Remove pontua√ß√£o (ex: '.', ',')
            token.text not in name_parts and # Remove partes do nome
            len(token.lemma_) > 3     # Remove palavras muito curtas
        ):
            lemmas.append(token.lemma_)
            
    processed_text = " ".join(lemmas)
    
    if not processed_text:
        st.warning("N√£o h√° texto suficiente para gerar a nuvem de palavras ap√≥s a limpeza.")
        return None

    # 4. Gerar a Nuvem de Palavras
    try:
        wordcloud = WordCloud(
            width=800, 
            height=400, 
            background_color='white',
            colormap='viridis',
            max_words=100
        ).generate(processed_text)
        
        # Converte a nuvem para uma imagem que o Streamlit possa exibir
        image = wordcloud.to_image()
        return image
    except ValueError:
        st.info("Texto insuficiente para gerar a nuvem de palavras.")
        return None

# --- Interface do Usu√°rio (Streamlit) ---

st.title("ü§ñ Ferramenta de An√°lise Pol√≠tica Automatizada")
st.markdown("Monitore a percep√ß√£o p√∫blica de deputados federais atrav√©s de not√≠cias recentes.")

# Entrada do usu√°rio
deputy_name = st.text_input("Digite o nome do Deputado Federal:", placeholder="Ex: Arthur Lira")

if st.button("Analisar Parlamentar"):
    if not deputy_name:
        st.error("Por favor, digite um nome para pesquisar.")
    elif not model:
         st.error("A aplica√ß√£o n√£o pode funcionar sem a API Key do Gemini.")
    else:
        with st.spinner(f"Buscando e analisando not√≠cias sobre {deputy_name}..."):
            
            # 1. Buscar Not√≠cias
            news_text, articles = fetch_news(deputy_name)
            
            if news_text:
                # 2. Gerar Resumo Anal√≠tico (Gemini)
                st.subheader("1. Relat√≥rio Textual Anal√≠tico (via Gemini)")
                summary = summarize_with_gemini(news_text)
                st.write(summary)
                
                # 3. Gerar Relat√≥rio Visual (Word Cloud)
                st.subheader("2. Relat√≥rio Visual (Nuvem de Palavras)")
                st.markdown(
                    "Termos e conceitos mais frequentes associados ao parlamentar "
                    "(ap√≥s remo√ß√£o de stopwords e do nome do deputado)."
                )
                
                wordcloud_image = clean_text_and_generate_wordcloud(news_text, deputy_name)
                
                if wordcloud_image:
                    st.image(wordcloud_image, use_column_width=True)
                
                # B√¥nus: Mostrar as fontes das not√≠cias
                with st.expander("Ver fontes das not√≠cias coletadas"):
                    for art in articles:
                        st.markdown(f"- [{art['title']}]({art['url']}) *({art['publisher']['title']})*")
